{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0edc40c60d349445bffa00379afa514e23d0b91277b1f887615985d25be917523",
   "display_name": "Python 3.7.10 64-bit ('topic_modeling': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Compare normalization of tokens via stemming and lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO measure vocab overlap after pruning\n",
    "# TODO Visualize author correlations for each stemmed model in a way that they can be compared\n",
    "# TODO \"Influential Words\" and stemming conflation (sec 5.5 in Apples to Apple)\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from topic_modeling.analysis import *\n",
    "from topic_modeling.mallet_parser import *\n",
    "import topic_modeling.preprocessing as preprocessing\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "all_stemmers = ['pymystem3', 'snowball', 'stanza', 'truncate']\n",
    "\n",
    "def read_tf_csv(filepath):\n",
    "    return pd.read_csv(filepath, sep='\\t', encoding='utf-8', \n",
    "                       names=['token', 'term_freq'], usecols=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in original author counts\n",
    "UNSTEMMED_CORPUS_DIR = Path('/home/virginia/workspace/topic-modeling-study/russian_novels') \n",
    "ORIGINAL_CORPUS = UNSTEMMED_CORPUS_DIR / 'russian_novels.tsv'\n",
    "ORIGINAL_CORPUS_COUNTS = UNSTEMMED_CORPUS_DIR / 'russian_novels_counts.tsv'\n",
    "ORIGINAL_PRUNED_COUNTS = UNSTEMMED_CORPUS_DIR  / 'russian_novels_pruned_counts.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unpruned corpus:\n",
      "Character to token ratio: 5.211265027848076\n",
      "Dataframe size: 319459\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  token  term_freq\n",
       "0     и     247754\n",
       "1    не     122673\n",
       "2    на      91762\n",
       "3   что      88897\n",
       "4     в     145809"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>и</td>\n      <td>247754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>не</td>\n      <td>122673</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>на</td>\n      <td>91762</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>что</td>\n      <td>88897</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>в</td>\n      <td>145809</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "original_tf = read_tf_csv(ORIGINAL_CORPUS_COUNTS)\n",
    "print(\"Unpruned corpus:\")\n",
    "print(\"Character to token ratio:\", get_character_token_ratio(original_tf, 'token', 'term_freq'))\n",
    "print(\"Dataframe size:\", len(original_tf))\n",
    "original_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Character to token ratio: 6.678288550826788\nDataframe size: 80540\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     token  term_freq\n",
       "0   совсем       3618\n",
       "1     стал       3395\n",
       "2     этой       3205\n",
       "3  которые       3638\n",
       "4    много       3355"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>совсем</td>\n      <td>3618</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>стал</td>\n      <td>3395</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>этой</td>\n      <td>3205</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>которые</td>\n      <td>3638</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>много</td>\n      <td>3355</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "original_pruned_tf = read_tf_csv(ORIGINAL_PRUNED_COUNTS)\n",
    "print(\"Character to token ratio:\", get_character_token_ratio(original_pruned_tf, 'token', 'term_freq'))\n",
    "original_pruned_vocab_size =  len(original_pruned_tf)\n",
    "original_pruned_token_count = original_pruned_tf[\"term_freq\"].sum()\n",
    "print(\"Dataframe size:\", original_pruned_vocab_size)\n",
    "original_pruned_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words pruned from original vocab: 238919\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  token  term_freq\n0     и     247754\n1    не     122673\n2    на      91762\n3   что      88897\n4     в     145809",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>и</td>\n      <td>247754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>не</td>\n      <td>122673</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>на</td>\n      <td>91762</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>что</td>\n      <td>88897</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>в</td>\n      <td>145809</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "             token  term_freq\n319454  abencerage          1\n319455         abc          1\n319456      abbasi          1\n319457         aaa          1\n319458           á          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>319454</th>\n      <td>abencerage</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>319455</th>\n      <td>abc</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>319456</th>\n      <td>abbasi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>319457</th>\n      <td>aaa</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>319458</th>\n      <td>á</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "original_stop_words = original_tf[~original_tf['token'].isin(original_pruned_tf['token'])].dropna()\n",
    "print(\"Number of words pruned from original vocab:\", len(original_stop_words))\n",
    "display(original_stop_words.head())\n",
    "display(original_stop_words.tail())"
   ]
  },
  {
   "source": [
    "# Comparison with stemmed corpus\n",
    "Keep lemmas/stems, the vocabulary elements in stemmed corpora, as the 'normalized' column and the actual raw 'tokens', the vocabulary elements in the original corpus as 'token' column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     author   token normalized  count\n",
       "0  Turgenev    было       быть    919\n",
       "1  Turgenev   тихое      тихий      9\n",
       "2  Turgenev  летнее     летний      3\n",
       "3  Turgenev    утро       утро     58\n",
       "4  Turgenev  солнце     солнце     42"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>token</th>\n      <th>normalized</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Turgenev</td>\n      <td>было</td>\n      <td>быть</td>\n      <td>919</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Turgenev</td>\n      <td>тихое</td>\n      <td>тихий</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Turgenev</td>\n      <td>летнее</td>\n      <td>летний</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Turgenev</td>\n      <td>утро</td>\n      <td>утро</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Turgenev</td>\n      <td>солнце</td>\n      <td>солнце</td>\n      <td>42</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Just start by comparing pymystem to original \n",
    "stemmer = 'pymystem3'\n",
    "stemmed_dir_path = Path(f'/home/virginia/workspace/topic-modeling-study/russian_novels_{stemmer}')\n",
    "stemmed_experiment_path = stemmed_dir_path / f'russian_novels_{stemmer}_100topics_1000iters'\n",
    "stemmed_lemma_counts_path = stemmed_dir_path / f'russian_novels_{stemmer}_lemma_counts.tsv'\n",
    "# This gets the counds of all lemma/token pairs\n",
    "stemmed_token_counts_by_author = pd.read_csv(stemmed_lemma_counts_path, sep='\\t', header=0, encoding='utf-8')\n",
    "stemmed_token_counts_by_author.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total tokens 6084073\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       token normalized  pair_count\n80685      и          и      248005\n18617      в          в      145881\n131444    не         не      122758\n122817    на         на       91965\n297786   что        что       89135",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>normalized</th>\n      <th>pair_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>80685</th>\n      <td>и</td>\n      <td>и</td>\n      <td>248005</td>\n    </tr>\n    <tr>\n      <th>18617</th>\n      <td>в</td>\n      <td>в</td>\n      <td>145881</td>\n    </tr>\n    <tr>\n      <th>131444</th>\n      <td>не</td>\n      <td>не</td>\n      <td>122758</td>\n    </tr>\n    <tr>\n      <th>122817</th>\n      <td>на</td>\n      <td>на</td>\n      <td>91965</td>\n    </tr>\n    <tr>\n      <th>297786</th>\n      <td>что</td>\n      <td>что</td>\n      <td>89135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Remove the by-author aggregation to get total token, lemma pair counts\n",
    "token_lemma_counts = stemmed_token_counts_by_author.groupby([\"token\", \"normalized\"]).agg({\"count\":\"sum\"}).reset_index().sort_values(['count'], ascending=False).rename(columns={'count':'pair_count'})\n",
    "# Sanity check pair count - should match # of tokens in corpus\n",
    "print(\"Total tokens\", token_lemma_counts[\"pair_count\"].sum())\n",
    "display(token_lemma_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      normalized  num_word_types\n49594   подымать              93\n54756  принимать              90\n19550   замечать              89\n13929     давать              84\n19680   занимать              83",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized</th>\n      <th>num_word_types</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49594</th>\n      <td>подымать</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>54756</th>\n      <td>принимать</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>19550</th>\n      <td>замечать</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>13929</th>\n      <td>давать</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>19680</th>\n      <td>занимать</td>\n      <td>83</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   normalized  num_word_types         token  pair_count\n0    подымать              93        поднял         796\n1    подымать              93        подняв         316\n2    подымать              93       подняла         289\n3    подымать              93      поднимая         248\n4    подымать              93       поднять         196\n5    подымать              93       подняли         117\n6    подымать              93      поднимал         111\n7    подымать              93     поднимать          52\n8    подымать              93     поднимала          40\n9    подымать              93       подымая          36\n10   подымать              93      подымать          33\n11   подымать              93     поднимали          33\n12   подымать              93     поднимает          28\n13   подымать              93     поднятыми          27\n14   подымать              93      поднятый          26\n15   подымать              93       подымал          22\n16   подымать              93      поднятые          19\n17   подымать              93      поднятым          17\n18   подымать              93      подымает          15\n19   подымать              93       подняло          14\n20   подымать              93       поднялъ          13\n21   подымать              93       подымет          13\n22   подымать              93      поднятой          12\n23   подымать              93      поднявши          12\n24   подымать              93      поднятую          11\n25   подымать              93      поднятых          11\n26   подымать              93      поднимет          10\n27   подымать              93       подними          10\n28   подымать              93     поднимают          10\n29   подымать              93      подымала           9\n30   подымать              93        поднят           9\n31   подымать              93      подымали           8\n32   подымать              93        подыму           8\n33   подымать              93     поднимало           7\n34   подымать              93      поднятая           7\n35   подымать              93     поднимите           7\n36   подымать              93       поднята           7\n37   подымать              93       подымай           7\n38   подымать              93        подыми           7\n39   подымать              93       подымем           7\n40   подымать              93       подняты           6\n41   подымать              93       подниму           5\n42   подымать              93      поднимаю           5\n43   подымать              93       поднявъ           5\n44   подымать              93       поднято           5\n45   подымать              93      подымают           4\n46   подымать              93       подымут           4\n47   подымать              93     поднявший           4\n48   подымать              93      поднимут           4\n49   подымать              93     поднимешь           4\n50   подымать              93      поднятое           4\n51   подымать              93     поднятого           4\n52   подымать              93      подымешь           3\n53   подымать              93      подымете           3\n54   подымать              93   поднимавший           3\n55   подымать              93    поднимайте           3\n56   подымать              93     поднимете           2\n57   подымать              93      поднимем           2\n58   подымать              93   поднимавшей           2\n59   подымать              93  поднимавшего           2\n60   подымать              93    поднимаешь           2\n61   подымать              93     поднимаем           2\n62   подымать              93     поднявших           2\n63   подымать              93     поднявшая           2\n64   подымать              93     поднявшее           2\n65   подымать              93     поднятымъ           2\n66   подымать              93      подымите           2\n67   подымать              93       подымаю           2\n68   подымать              93     подымайте           2\n69   подымать              93   поднимаемых           1\n70   подымать              93   поднимавшим           1\n71   подымать              93   поднимавших           1\n72   подымать              93   поднимаемая           1\n73   подымать              93    поднимаете           1\n74   подымать              93   поднимающей           1\n75   подымать              93   поднимающий           1\n76   подымать              93   поднимающих           1\n77   подымать              93   поднимающую           1\n78   подымать              93     поднимутъ           1\n79   подымать              93    поднявшего           1\n80   подымать              93      поднятом           1\n81   подымать              93      поднятою           1\n82   подымать              93     поднятыхъ           1\n83   подымать              93    подымающий           1\n84   подымать              93    подымающих           1\n85   подымать              93    подымающую           1\n86   подымать              93      подымало           1\n87   подымать              93     подымаешь           1\n88   подымать              93     подымаете           1\n89   подымать              93      подымаем           1\n90   подымать              93    подымавший           1\n91   подымать              93    подымавшим           1\n92   подымать              93    подымавшую           1\n93  принимать              90       принять         465\n94  принимать              90        принял         435\n95  принимать              90       приняла         193\n96  принимать              90     принимать         189\n97  принимать              90      принимал         160\n98  принимать              90       приняли         151\n99  принимать              90     принимает         130",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized</th>\n      <th>num_word_types</th>\n      <th>token</th>\n      <th>pair_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднял</td>\n      <td>796</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подняв</td>\n      <td>316</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подняла</td>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимая</td>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднять</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подняли</td>\n      <td>117</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимал</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимать</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимала</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымая</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымать</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимали</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимает</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятыми</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятый</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымал</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятые</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятым</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымает</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подняло</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднялъ</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымет</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятой</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявши</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятую</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятых</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимет</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подними</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимают</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымала</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднят</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымали</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подыму</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимало</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятая</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимите</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднята</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымай</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подыми</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымем</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подняты</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подниму</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимаю</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявъ</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднято</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымают</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымут</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявший</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимут</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимешь</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятое</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятого</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымешь</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымете</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимавший</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимайте</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимете</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимем</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимавшей</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимавшего</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимаешь</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимаем</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявших</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявшая</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявшее</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятымъ</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымите</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымаю</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымайте</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимаемых</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимавшим</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимавших</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимаемая</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимаете</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимающей</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимающий</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимающих</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимающую</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднимутъ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднявшего</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятом</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятою</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>поднятыхъ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымающий</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымающих</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымающую</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымало</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымаешь</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымаете</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымаем</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымавший</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымавшим</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>подымать</td>\n      <td>93</td>\n      <td>подымавшую</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>принять</td>\n      <td>465</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>принял</td>\n      <td>435</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>приняла</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>принимать</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>принимал</td>\n      <td>160</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>приняли</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>принимать</td>\n      <td>90</td>\n      <td>принимает</td>\n      <td>130</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Do the normalized vocab elements with very high word_type counts make sense? \n",
    "count_word_types = token_lemma_counts.groupby([\"normalized\"]).size().reset_index(name=\"num_word_types\").sort_values(\"num_word_types\", ascending=False)\n",
    "display(count_word_types.head())\n",
    "count_word_types = pd.merge(count_word_types, token_lemma_counts, on=\"normalized\")\n",
    "display(count_word_types.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unpruned\nCharacter to token ratio: 5.191822977797933\nDataframe size: 80163\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  normalized  term_freq\n",
       "0          и     248005\n",
       "1          в     149230\n",
       "2         не     122761\n",
       "3         на      91969\n",
       "4          с      76022"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>и</td>\n      <td>248005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>в</td>\n      <td>149230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>не</td>\n      <td>122761</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>на</td>\n      <td>91969</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>с</td>\n      <td>76022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Vocab and counts of LEMMAS in unpruned corpus\n",
    "stemmed_unpruned_tf = read_tf_csv(stemmed_dir_path/f'russian_novels_{stemmer}_counts.tsv').rename(columns={\"token\":\"normalized\"})\n",
    "print(\"Unpruned\")\n",
    "print(\"Character to token ratio:\", get_character_token_ratio(stemmed_unpruned_tf, 'normalized', 'term_freq'))\n",
    "print(\"Dataframe size:\", len(stemmed_unpruned_tf))\n",
    "stemmed_unpruned_tf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pruned\nCharacter to token ratio: 7.252728765481368\nVocab size: 32648\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  normalized  term_freq\n",
       "0     сейчас       3532\n",
       "1     каждый       3594\n",
       "2       ночь       3885\n",
       "3    должный       3519\n",
       "4       душа       3863"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>сейчас</td>\n      <td>3532</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>каждый</td>\n      <td>3594</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ночь</td>\n      <td>3885</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>должный</td>\n      <td>3519</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>душа</td>\n      <td>3863</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Vocab and counts of LEMMAS in pruned corpus\n",
    "stemmed_pruned_tf = read_tf_csv(stemmed_dir_path/f'russian_novels_{stemmer}_pruned_counts.tsv').rename(columns={'token':'normalized'})\n",
    "stemmed_pruned_vocab_size = len(stemmed_pruned_tf)\n",
    "print(\"Pruned\")\n",
    "print(\"Character to token ratio:\", get_character_token_ratio(stemmed_pruned_tf, 'normalized', 'term_freq'))\n",
    "print(\"Vocab size:\", stemmed_pruned_vocab_size)\n",
    "stemmed_pruned_tf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words pruned from stemmed vocab: 47515\nTotal stopped tokens 3107269\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "         normalized  term_freq\n0                 и     248005\n1                 в     149230\n2                не     122761\n3                на      91969\n4                 с      76022\n...             ...        ...\n80158          аать          1\n80159        аасбаа          1\n80160  аардваркский          1\n80161     аардварка          1\n80162          аааа          1\n\n[47515 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>и</td>\n      <td>248005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>в</td>\n      <td>149230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>не</td>\n      <td>122761</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>на</td>\n      <td>91969</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>с</td>\n      <td>76022</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80158</th>\n      <td>аать</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80159</th>\n      <td>аасбаа</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80160</th>\n      <td>аардваркский</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80161</th>\n      <td>аардварка</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>80162</th>\n      <td>аааа</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>47515 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Get dataframe with counts of stopped lemmas, token pairs in stemmed corpus\n",
    "stemmed_stop_words_df = stemmed_unpruned_tf[~stemmed_unpruned_tf['normalized'].isin(stemmed_pruned_tf['normalized'])].dropna()\n",
    "print(\"Number of words pruned from stemmed vocab:\", len(stemmed_stop_words_df))\n",
    "# Sanity check against comparison spreadsheet\n",
    "total_stopped_tokens =  stemmed_stop_words_df[\"term_freq\"].sum()\n",
    "print(\"Total stopped tokens\", total_stopped_tokens)\n",
    "display(stemmed_stop_words_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Joining token,lemma pair counts with stemmed stop words\n",
      "66594 total stopped (token, lemma) pairs\n",
      "Sanity check: total stopped tokens according to groupby 'pair_count' (does this match previous cell?) 3107269\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "              token    normalized  pair_count  term_freq\n0                 и             и      248005     248005\n1                 в             в      145881     149230\n2                въ             в        3349     149230\n3                не            не      122758     122761\n4                нe            не           3     122761\n...             ...           ...         ...        ...\n66589          аать          аать           1          1\n66590        аасбаа        аасбаа           1          1\n66591  аардваркской  аардваркский           1          1\n66592     аардварка     аардварка           1          1\n66593          аааа          аааа           1          1\n\n[66594 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>normalized</th>\n      <th>pair_count</th>\n      <th>term_freq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>и</td>\n      <td>и</td>\n      <td>248005</td>\n      <td>248005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>в</td>\n      <td>в</td>\n      <td>145881</td>\n      <td>149230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>въ</td>\n      <td>в</td>\n      <td>3349</td>\n      <td>149230</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>не</td>\n      <td>не</td>\n      <td>122758</td>\n      <td>122761</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>нe</td>\n      <td>не</td>\n      <td>3</td>\n      <td>122761</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66589</th>\n      <td>аать</td>\n      <td>аать</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66590</th>\n      <td>аасбаа</td>\n      <td>аасбаа</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66591</th>\n      <td>аардваркской</td>\n      <td>аардваркский</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66592</th>\n      <td>аардварка</td>\n      <td>аардварка</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>66593</th>\n      <td>аааа</td>\n      <td>аааа</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>66594 rows × 4 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "print(\"Joining token,lemma pair counts with stemmed stop words\")\n",
    "stopped_token_lemma_pairs = pd.merge(token_lemma_counts, stemmed_stop_words_df, how='right', on=['normalized'])\n",
    "print(len(stopped_token_lemma_pairs), \"total stopped (token, lemma) pairs\")\n",
    "total_stopped_pair_counts = stopped_token_lemma_pairs[\"pair_count\"].sum()\n",
    "print(\"Sanity check: total stopped tokens according to groupby 'pair_count' (does this match previous cell?)\", total_stopped_pair_counts)\n",
    "assert total_stopped_tokens == total_stopped_pair_counts\n",
    "\n",
    "display(stopped_token_lemma_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "These (token,lemma) pairs are pruned due to stemming putting the normalized form over the max-df threshold:\n",
      "Number of original vocab (AKA number of token-lemma pairs) removed by stemming putting the normalized form above the max df threshold: 2566\n",
      "Number of normalized forms (stems/lemmas) affected: 609\n",
      "Actual token count removed by stemming putting the normalized form above the max df threshold: 688006\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "      token normalized  pair_count  term_freq_normalized  \\\n0        въ          в        3349                149230   \n1        съ          с        1918                 76022   \n2      чему        что        1002                 96162   \n3      чѣмъ        что          58                 96162   \n4      чѣмъ        чем          80                  4780   \n5       чём        что          40                 96162   \n6      чемъ        что          32                 96162   \n7      чемъ        чем          55                  4780   \n8       чeм        что           5                 96162   \n9       чeм        чем          16                  4780   \n10     буду       быть        1860                 80855   \n11    будут       быть        1018                 80855   \n12    будем       быть         804                 80855   \n13   будешь       быть         620                 80855   \n14     будь       быть         524                 80855   \n15   будете       быть         491                 80855   \n16     былъ       быть         462                 80855   \n17   будьте       быть         272                 80855   \n18   будучи       быть         229                 80855   \n19     суть       быть          28                 80855   \n20   будетъ       быть          28                 80855   \n21   будутъ       быть          25                 80855   \n22      быв       быть          24                 80855   \n23  будемте       быть          24                 80855   \n24   будемъ       быть          17                 80855   \n25    бывши       быть          13                 80855   \n26   бывший       быть          10                 80855   \n27   бывшие       быть           8                 80855   \n28  бывшего       быть           7                 80855   \n29     ѣсть       быть           7                 80855   \n30     быти       быть           5                 80855   \n31   бывшей       быть           5                 80855   \n32   бывшею       быть           4                 80855   \n33  бывшему       быть           2                 80855   \n34   бывшее       быть           1                 80855   \n35  бывшими       быть           1                 80855   \n36     нему         он        2916                136983   \n37      нем         он        2112                136983   \n38      онъ         он        1734                136983   \n39     нимъ         он         164                136983   \n40      имъ         он          88                136983   \n41     немъ         он          83                136983   \n42      нём         он          71                136983   \n43     какъ        как        1387                 51323   \n44       къ          к        1021                 38014   \n45     мной          я        1733                115087   \n46     мною          я        1154                115087   \n47      мнѣ          я         665                115087   \n48      мнe          я         316                115087   \n49     этим        это         858                 39769   \n50     этим       этот        1172                 31959   \n51    этому        это         429                 39769   \n52    этому       этот         725                 31959   \n53    этомъ        это          55                 39769   \n54    этимъ        это          31                 39769   \n55    этимъ       этот           2                 31959   \n56     тому         то        1883                 38283   \n57     тому        тот         391                 16554   \n58     тѣмъ         то         105                 38283   \n59     томъ         то          56                 38283   \n60      тeм         то          50                 38283   \n61      нею        она        1784                 73529   \n62       ею        она         801                 73529   \n63       ея        она         769                 73529   \n64       её        она         299                 73529   \n65       её         ее         410                 11894   \n66      неё        она         171                 73529   \n67      нея        она         119                 73529   \n68     этой       этот        3219                 31959   \n69      эту       этот        2980                 31959   \n70      эта       этот        2921                 31959   \n71     этих       этот        2057                 31959   \n72    этими       этот         376                 31959   \n73     этою       этот         173                 31959   \n74    этотъ       этот          76                 31959   \n75    этихъ       этот          39                 31959   \n76     такъ        так         780                 27556   \n77     таке        так           5                 27556   \n78     таку        так           3                 27556   \n79     весь       весь        2640                 26521   \n80      всю       весь        2467                 26521   \n81      вся       весь        1918                 26521   \n82     всем       весь        1194                 26521   \n83     всем        все        1860                 27012   \n84     всей       весь        1054                 26521   \n85      всё       весь         947                 26521   \n86      всё        все        3010                 27012   \n87    всего       весь         679                 26521   \n88    всего        все        1923                 27012   \n89    всеми       весь         518                 26521   \n90    всеми        все         259                 27012   \n91    всему       весь         408                 26521   \n92    всему        все         350                 27012   \n93     всею       весь         188                 26521   \n94    всѣхъ       весь          59                 26521   \n95    всѣхъ        все          63                 27012   \n96      всѣ       весь          32                 26521   \n97      всѣ        все         273                 27012   \n98     всём       весь          19                 26521   \n99     всём        все           8                 27012   \n\n    term_freq_original_token  \n0                       3332  \n1                       1887  \n2                        999  \n3                        128  \n4                        128  \n5                         40  \n6                         81  \n7                         81  \n8                         21  \n9                         21  \n10                      1858  \n11                      1015  \n12                       804  \n13                       620  \n14                       523  \n15                       491  \n16                       462  \n17                       271  \n18                       229  \n19                       109  \n20                       195  \n21                        25  \n22                        24  \n23                        24  \n24                        17  \n25                        13  \n26                       218  \n27                        66  \n28                       126  \n29                         6  \n30                         5  \n31                        53  \n32                         5  \n33                        26  \n34                        28  \n35                        10  \n36                      2924  \n37                      3321  \n38                      1733  \n39                       164  \n40                        88  \n41                        83  \n42                        72  \n43                      1288  \n44                      1020  \n45                      1731  \n46                      1154  \n47                       660  \n48                       316  \n49                      2019  \n50                      2019  \n51                      1148  \n52                      1148  \n53                        54  \n54                        33  \n55                        33  \n56                      2278  \n57                      2278  \n58                       108  \n59                        56  \n60                        50  \n61                      1782  \n62                       801  \n63                       884  \n64                       709  \n65                       709  \n66                       171  \n67                       135  \n68                      3205  \n69                      2960  \n70                      2905  \n71                      2047  \n72                       372  \n73                       172  \n74                        74  \n75                        39  \n76                       755  \n77                         5  \n78                         6  \n79                      2627  \n80                      2459  \n81                      1908  \n82                      3050  \n83                      3050  \n84                      1051  \n85                      3941  \n86                      3941  \n87                      3278  \n88                      3278  \n89                       775  \n90                       775  \n91                       755  \n92                       755  \n93                       187  \n94                       122  \n95                       122  \n96                       305  \n97                       305  \n98                        27  \n99                        27  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>normalized</th>\n      <th>pair_count</th>\n      <th>term_freq_normalized</th>\n      <th>term_freq_original_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>въ</td>\n      <td>в</td>\n      <td>3349</td>\n      <td>149230</td>\n      <td>3332</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>съ</td>\n      <td>с</td>\n      <td>1918</td>\n      <td>76022</td>\n      <td>1887</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>чему</td>\n      <td>что</td>\n      <td>1002</td>\n      <td>96162</td>\n      <td>999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>чѣмъ</td>\n      <td>что</td>\n      <td>58</td>\n      <td>96162</td>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>чѣмъ</td>\n      <td>чем</td>\n      <td>80</td>\n      <td>4780</td>\n      <td>128</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>чём</td>\n      <td>что</td>\n      <td>40</td>\n      <td>96162</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>чемъ</td>\n      <td>что</td>\n      <td>32</td>\n      <td>96162</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>чемъ</td>\n      <td>чем</td>\n      <td>55</td>\n      <td>4780</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>чeм</td>\n      <td>что</td>\n      <td>5</td>\n      <td>96162</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>чeм</td>\n      <td>чем</td>\n      <td>16</td>\n      <td>4780</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>буду</td>\n      <td>быть</td>\n      <td>1860</td>\n      <td>80855</td>\n      <td>1858</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>будут</td>\n      <td>быть</td>\n      <td>1018</td>\n      <td>80855</td>\n      <td>1015</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>будем</td>\n      <td>быть</td>\n      <td>804</td>\n      <td>80855</td>\n      <td>804</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>будешь</td>\n      <td>быть</td>\n      <td>620</td>\n      <td>80855</td>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>будь</td>\n      <td>быть</td>\n      <td>524</td>\n      <td>80855</td>\n      <td>523</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>будете</td>\n      <td>быть</td>\n      <td>491</td>\n      <td>80855</td>\n      <td>491</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>былъ</td>\n      <td>быть</td>\n      <td>462</td>\n      <td>80855</td>\n      <td>462</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>будьте</td>\n      <td>быть</td>\n      <td>272</td>\n      <td>80855</td>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>будучи</td>\n      <td>быть</td>\n      <td>229</td>\n      <td>80855</td>\n      <td>229</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>суть</td>\n      <td>быть</td>\n      <td>28</td>\n      <td>80855</td>\n      <td>109</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>будетъ</td>\n      <td>быть</td>\n      <td>28</td>\n      <td>80855</td>\n      <td>195</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>будутъ</td>\n      <td>быть</td>\n      <td>25</td>\n      <td>80855</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>быв</td>\n      <td>быть</td>\n      <td>24</td>\n      <td>80855</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>будемте</td>\n      <td>быть</td>\n      <td>24</td>\n      <td>80855</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>будемъ</td>\n      <td>быть</td>\n      <td>17</td>\n      <td>80855</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>бывши</td>\n      <td>быть</td>\n      <td>13</td>\n      <td>80855</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>бывший</td>\n      <td>быть</td>\n      <td>10</td>\n      <td>80855</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>бывшие</td>\n      <td>быть</td>\n      <td>8</td>\n      <td>80855</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>бывшего</td>\n      <td>быть</td>\n      <td>7</td>\n      <td>80855</td>\n      <td>126</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>ѣсть</td>\n      <td>быть</td>\n      <td>7</td>\n      <td>80855</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>быти</td>\n      <td>быть</td>\n      <td>5</td>\n      <td>80855</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>бывшей</td>\n      <td>быть</td>\n      <td>5</td>\n      <td>80855</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>бывшею</td>\n      <td>быть</td>\n      <td>4</td>\n      <td>80855</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>бывшему</td>\n      <td>быть</td>\n      <td>2</td>\n      <td>80855</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>бывшее</td>\n      <td>быть</td>\n      <td>1</td>\n      <td>80855</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>бывшими</td>\n      <td>быть</td>\n      <td>1</td>\n      <td>80855</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>нему</td>\n      <td>он</td>\n      <td>2916</td>\n      <td>136983</td>\n      <td>2924</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>нем</td>\n      <td>он</td>\n      <td>2112</td>\n      <td>136983</td>\n      <td>3321</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>онъ</td>\n      <td>он</td>\n      <td>1734</td>\n      <td>136983</td>\n      <td>1733</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>нимъ</td>\n      <td>он</td>\n      <td>164</td>\n      <td>136983</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>имъ</td>\n      <td>он</td>\n      <td>88</td>\n      <td>136983</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>немъ</td>\n      <td>он</td>\n      <td>83</td>\n      <td>136983</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>нём</td>\n      <td>он</td>\n      <td>71</td>\n      <td>136983</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>какъ</td>\n      <td>как</td>\n      <td>1387</td>\n      <td>51323</td>\n      <td>1288</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>къ</td>\n      <td>к</td>\n      <td>1021</td>\n      <td>38014</td>\n      <td>1020</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>мной</td>\n      <td>я</td>\n      <td>1733</td>\n      <td>115087</td>\n      <td>1731</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>мною</td>\n      <td>я</td>\n      <td>1154</td>\n      <td>115087</td>\n      <td>1154</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>мнѣ</td>\n      <td>я</td>\n      <td>665</td>\n      <td>115087</td>\n      <td>660</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>мнe</td>\n      <td>я</td>\n      <td>316</td>\n      <td>115087</td>\n      <td>316</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>этим</td>\n      <td>это</td>\n      <td>858</td>\n      <td>39769</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>этим</td>\n      <td>этот</td>\n      <td>1172</td>\n      <td>31959</td>\n      <td>2019</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>этому</td>\n      <td>это</td>\n      <td>429</td>\n      <td>39769</td>\n      <td>1148</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>этому</td>\n      <td>этот</td>\n      <td>725</td>\n      <td>31959</td>\n      <td>1148</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>этомъ</td>\n      <td>это</td>\n      <td>55</td>\n      <td>39769</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>этимъ</td>\n      <td>это</td>\n      <td>31</td>\n      <td>39769</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>этимъ</td>\n      <td>этот</td>\n      <td>2</td>\n      <td>31959</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>тому</td>\n      <td>то</td>\n      <td>1883</td>\n      <td>38283</td>\n      <td>2278</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>тому</td>\n      <td>тот</td>\n      <td>391</td>\n      <td>16554</td>\n      <td>2278</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>тѣмъ</td>\n      <td>то</td>\n      <td>105</td>\n      <td>38283</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>томъ</td>\n      <td>то</td>\n      <td>56</td>\n      <td>38283</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>тeм</td>\n      <td>то</td>\n      <td>50</td>\n      <td>38283</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>нею</td>\n      <td>она</td>\n      <td>1784</td>\n      <td>73529</td>\n      <td>1782</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>ею</td>\n      <td>она</td>\n      <td>801</td>\n      <td>73529</td>\n      <td>801</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>ея</td>\n      <td>она</td>\n      <td>769</td>\n      <td>73529</td>\n      <td>884</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>её</td>\n      <td>она</td>\n      <td>299</td>\n      <td>73529</td>\n      <td>709</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>её</td>\n      <td>ее</td>\n      <td>410</td>\n      <td>11894</td>\n      <td>709</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>неё</td>\n      <td>она</td>\n      <td>171</td>\n      <td>73529</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>нея</td>\n      <td>она</td>\n      <td>119</td>\n      <td>73529</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>этой</td>\n      <td>этот</td>\n      <td>3219</td>\n      <td>31959</td>\n      <td>3205</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>эту</td>\n      <td>этот</td>\n      <td>2980</td>\n      <td>31959</td>\n      <td>2960</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>эта</td>\n      <td>этот</td>\n      <td>2921</td>\n      <td>31959</td>\n      <td>2905</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>этих</td>\n      <td>этот</td>\n      <td>2057</td>\n      <td>31959</td>\n      <td>2047</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>этими</td>\n      <td>этот</td>\n      <td>376</td>\n      <td>31959</td>\n      <td>372</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>этою</td>\n      <td>этот</td>\n      <td>173</td>\n      <td>31959</td>\n      <td>172</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>этотъ</td>\n      <td>этот</td>\n      <td>76</td>\n      <td>31959</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>этихъ</td>\n      <td>этот</td>\n      <td>39</td>\n      <td>31959</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>такъ</td>\n      <td>так</td>\n      <td>780</td>\n      <td>27556</td>\n      <td>755</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>таке</td>\n      <td>так</td>\n      <td>5</td>\n      <td>27556</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>таку</td>\n      <td>так</td>\n      <td>3</td>\n      <td>27556</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>весь</td>\n      <td>весь</td>\n      <td>2640</td>\n      <td>26521</td>\n      <td>2627</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>всю</td>\n      <td>весь</td>\n      <td>2467</td>\n      <td>26521</td>\n      <td>2459</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>вся</td>\n      <td>весь</td>\n      <td>1918</td>\n      <td>26521</td>\n      <td>1908</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>всем</td>\n      <td>весь</td>\n      <td>1194</td>\n      <td>26521</td>\n      <td>3050</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>всем</td>\n      <td>все</td>\n      <td>1860</td>\n      <td>27012</td>\n      <td>3050</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>всей</td>\n      <td>весь</td>\n      <td>1054</td>\n      <td>26521</td>\n      <td>1051</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>всё</td>\n      <td>весь</td>\n      <td>947</td>\n      <td>26521</td>\n      <td>3941</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>всё</td>\n      <td>все</td>\n      <td>3010</td>\n      <td>27012</td>\n      <td>3941</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>всего</td>\n      <td>весь</td>\n      <td>679</td>\n      <td>26521</td>\n      <td>3278</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>всего</td>\n      <td>все</td>\n      <td>1923</td>\n      <td>27012</td>\n      <td>3278</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>всеми</td>\n      <td>весь</td>\n      <td>518</td>\n      <td>26521</td>\n      <td>775</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>всеми</td>\n      <td>все</td>\n      <td>259</td>\n      <td>27012</td>\n      <td>775</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>всему</td>\n      <td>весь</td>\n      <td>408</td>\n      <td>26521</td>\n      <td>755</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>всему</td>\n      <td>все</td>\n      <td>350</td>\n      <td>27012</td>\n      <td>755</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>всею</td>\n      <td>весь</td>\n      <td>188</td>\n      <td>26521</td>\n      <td>187</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>всѣхъ</td>\n      <td>весь</td>\n      <td>59</td>\n      <td>26521</td>\n      <td>122</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>всѣхъ</td>\n      <td>все</td>\n      <td>63</td>\n      <td>27012</td>\n      <td>122</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>всѣ</td>\n      <td>весь</td>\n      <td>32</td>\n      <td>26521</td>\n      <td>305</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>всѣ</td>\n      <td>все</td>\n      <td>273</td>\n      <td>27012</td>\n      <td>305</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>всём</td>\n      <td>весь</td>\n      <td>19</td>\n      <td>26521</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>всём</td>\n      <td>все</td>\n      <td>8</td>\n      <td>27012</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# What tokens were unstopped originally, but their lemmas became stopped by going over the 25% document frequency threshold? \n",
    "print(\"These (token,lemma) pairs are pruned due to stemming putting the normalized form over the max-df threshold:\")\n",
    "new_stopped_tokens_when_stemming = pd.merge(stopped_token_lemma_pairs, original_pruned_tf, how=\"inner\", on=[\"token\"], suffixes=(\"_normalized\", \"_original_token\"))\n",
    "print(\"Number of original vocab (AKA number of token-lemma pairs) removed by stemming putting the normalized form above the max df threshold:\", len(new_stopped_tokens_when_stemming))\n",
    "print(\"Number of normalized forms (stems/lemmas) affected:\", len(set(new_stopped_tokens_when_stemming[\"normalized\"])))\n",
    "print(\"Actual token count removed by stemming putting the normalized form above the max df threshold:\", new_stopped_tokens_when_stemming[\"term_freq_original_token\"].sum())\n",
    "display(new_stopped_tokens_when_stemming.head(100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "These are tokens which are kept (or added to the pruned vocabulary) through stemming, because conflation puts them with a normalized term with frequency higher than the min-tf threshold.\n",
      "Sanity check, does this match the token count for the pruned stemmed corpus? 2976804\n",
      "Number of original vocab items (AKA number of token-lemma pairs) kept/added to vocabulary: 158245\n",
      "Total tokens kept/added to vocabulary: 292362\n",
      "Total stems (normalized vocab items after stemming) affected: 28748\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       normalized  term_freq_normalized     token  pair_count  \\\n0          каждый                  3594    каждых           3   \n1          каждый                  3594    каждыя           1   \n2          каждый                  3594   каждыми           1   \n3            ночь                  3885     ночах           2   \n4         должный                  3519   должною           3   \n...           ...                   ...       ...         ...   \n158240     авдеев                     5   авдееву           1   \n158241     авдеев                     5  авдеевым           1   \n158242     авдеев                     5   авдеева           1   \n158243     абезон                     5   абезона           3   \n158244     абезон                     5    абезон           2   \n\n        term_freq_original_token  \n0                              3  \n1                              1  \n2                              1  \n3                              2  \n4                              3  \n...                          ...  \n158240                         1  \n158241                         1  \n158242                         1  \n158243                         3  \n158244                         2  \n\n[158245 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized</th>\n      <th>term_freq_normalized</th>\n      <th>token</th>\n      <th>pair_count</th>\n      <th>term_freq_original_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>каждый</td>\n      <td>3594</td>\n      <td>каждых</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>каждый</td>\n      <td>3594</td>\n      <td>каждыя</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>каждый</td>\n      <td>3594</td>\n      <td>каждыми</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ночь</td>\n      <td>3885</td>\n      <td>ночах</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>должный</td>\n      <td>3519</td>\n      <td>должною</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>158240</th>\n      <td>авдеев</td>\n      <td>5</td>\n      <td>авдееву</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>158241</th>\n      <td>авдеев</td>\n      <td>5</td>\n      <td>авдеевым</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>158242</th>\n      <td>авдеев</td>\n      <td>5</td>\n      <td>авдеева</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>158243</th>\n      <td>абезон</td>\n      <td>5</td>\n      <td>абезона</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>158244</th>\n      <td>абезон</td>\n      <td>5</td>\n      <td>абезон</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>158245 rows × 5 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# What tokens weren't in the pruned vocab originally because they were too rare? \n",
    "pruned_token_lemma_pairs = pd.merge(stemmed_pruned_tf, token_lemma_counts, on=\"normalized\")\n",
    "count_pruned_token_lemma_pairs = len(pruned_token_lemma_pairs)\n",
    "print(\"These are tokens which are kept (or added to the pruned vocabulary) through stemming, because conflation puts them with a normalized term with frequency higher than the min-tf threshold.\")\n",
    "pruned_stemmed_token_counts = pruned_token_lemma_pairs[\"pair_count\"].sum()\n",
    "print(\"Sanity check, does this match the token count for the pruned stemmed corpus?\", pruned_stemmed_token_counts)\n",
    "unstopped_by_stemming = pd.merge(pruned_token_lemma_pairs, original_stop_words, on=\"token\", how=\"inner\", suffixes=(\"_normalized\", \"_original_token\") )\n",
    "\n",
    "print(\"Number of original vocab items (AKA number of token-lemma pairs) kept/added to vocabulary:\", len(unstopped_by_stemming))\n",
    "print(\"Total tokens kept/added to vocabulary:\", unstopped_by_stemming[\"pair_count\"].sum())\n",
    "print(\"Total stems (normalized vocab items after stemming) affected:\", len(set(unstopped_by_stemming[\"normalized\"])))\n",
    "display(unstopped_by_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total lemmas/stems/normalized forms in intersection: 23407\n\t... as a percentage of the pruned stemmed vocabulary: 0.7169505023278608\nDistinct tokens (original vocab items) in intersection according to original corpus pairs: 77540\n\t... as a percentage of the original vocabulary size: 0.9627514278619319\n\t... as a percentage of the unique (token,lemma) pairs in the pruned stemmed corpus: 0.3233312206024619\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'count_token_lemma_pairs' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-619b5476ef85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t... as a percentage of the unique (token,lemma) pairs in the pruned stemmed corpus:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_original_tokens\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_pruned_token_lemma_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcount_token_lemma_pairs_intersect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpruned_token_intersection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pair_count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total tokens in intersection acccording to token,lemma pair counts:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_token_lemma_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t... as a percentage of the overall (token,lemma) pair counts in the full pruned stemmed corpus:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_token_lemma_pairs_intersect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpruned_stemmed_token_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcount_original_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpruned_token_intersection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"term_freq_original_token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_token_lemma_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "# Theoretically, 'pair_count' and 'term_freq_original_token' should match, but only if tokenizaiton is the same\n",
    "pruned_token_intersection = pd.merge(pruned_token_lemma_pairs, original_pruned_tf, on=\"token\", how=\"inner\", suffixes=(\"_normalized\", \"_original_token\"))\n",
    "num_lemmas = len(set(pruned_token_intersection[\"normalized\"]))\n",
    "print(\"Total lemmas/stems/normalized forms in intersection:\", num_lemmas)\n",
    "print(\"\\t... as a percentage of the pruned stemmed vocabulary:\", num_lemmas/stemmed_pruned_vocab_size)\n",
    "num_original_tokens = len(set(pruned_token_intersection[\"token\"]))\n",
    "print(\"Distinct tokens (original vocab items) in intersection according to original corpus pairs:\", num_original_tokens)\n",
    "print(\"\\t... as a percentage of the original vocabulary size:\", num_original_tokens/original_pruned_vocab_size)\n",
    "print(\"\\t... as a percentage of the unique (token,lemma) pairs in the pruned stemmed corpus:\", num_original_tokens/count_pruned_token_lemma_pairs)\n",
    "count_token_lemma_pairs_intersect = pruned_token_intersection[\"pair_count\"].sum()\n",
    "print(\"Total tokens in intersection acccording to token,lemma pair counts:\", count_token_lemma_pairs)\n",
    "print(\"\\t... as a percentage of the overall (token,lemma) pair counts in the full pruned stemmed corpus:\", count_token_lemma_pairs_intersect/pruned_stemmed_token_counts)\n",
    "count_original_tokens = pruned_token_intersection[\"term_freq_original_token\"].sum()\n",
    "print(\"Total tokens in intersection according to original token term freq counts:\", count_original_tokens)\n",
    "print(\"\\t... as a percentage of the overall token count in pruned original corpus:\", count_original_tokens/original_pruned_token_count)\n",
    "print(\"Intersection snippet:\")\n",
    "display(pruned_token_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "    tokens_metric  document_entropy  word-length  coherence  uniform_dist  \\\nid                                                                          \n0          8111.0            6.3338         5.65  -660.2322        4.3344   \n1          4972.0            4.4918         5.90  -633.5989        4.6936   \n2         83010.0            8.1134         5.10  -393.8316        3.4836   \n3          8054.0            4.9823         5.70  -413.8807        4.0737   \n4          7991.0            5.0774         6.50  -468.5135        4.7438   \n\n    corpus_dist  eff_num_words  token-doc-diff  rank_1_docs  allocation_ratio  \\\nid                                                                              \n0        3.9184       144.7236          0.0082       0.0141             0.000   \n1        4.2196       102.7199          0.0242       0.1731             0.024   \n2        2.0321       525.2401          0.0003       0.0259             0.000   \n3        3.9270       154.0240          0.0486       0.0758             0.000   \n4        3.8186        92.4072          0.0390       0.3162             0.000   \n\n    allocation_count  exclusivity  \nid                                 \n0             0.0019       0.5346  \n1             0.1394       0.6468  \n2             0.0043       0.1874  \n3             0.0072       0.5684  \n4             0.0909       0.5532  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens_metric</th>\n      <th>document_entropy</th>\n      <th>word-length</th>\n      <th>coherence</th>\n      <th>uniform_dist</th>\n      <th>corpus_dist</th>\n      <th>eff_num_words</th>\n      <th>token-doc-diff</th>\n      <th>rank_1_docs</th>\n      <th>allocation_ratio</th>\n      <th>allocation_count</th>\n      <th>exclusivity</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8111.0</td>\n      <td>6.3338</td>\n      <td>5.65</td>\n      <td>-660.2322</td>\n      <td>4.3344</td>\n      <td>3.9184</td>\n      <td>144.7236</td>\n      <td>0.0082</td>\n      <td>0.0141</td>\n      <td>0.000</td>\n      <td>0.0019</td>\n      <td>0.5346</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4972.0</td>\n      <td>4.4918</td>\n      <td>5.90</td>\n      <td>-633.5989</td>\n      <td>4.6936</td>\n      <td>4.2196</td>\n      <td>102.7199</td>\n      <td>0.0242</td>\n      <td>0.1731</td>\n      <td>0.024</td>\n      <td>0.1394</td>\n      <td>0.6468</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>83010.0</td>\n      <td>8.1134</td>\n      <td>5.10</td>\n      <td>-393.8316</td>\n      <td>3.4836</td>\n      <td>2.0321</td>\n      <td>525.2401</td>\n      <td>0.0003</td>\n      <td>0.0259</td>\n      <td>0.000</td>\n      <td>0.0043</td>\n      <td>0.1874</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8054.0</td>\n      <td>4.9823</td>\n      <td>5.70</td>\n      <td>-413.8807</td>\n      <td>4.0737</td>\n      <td>3.9270</td>\n      <td>154.0240</td>\n      <td>0.0486</td>\n      <td>0.0758</td>\n      <td>0.000</td>\n      <td>0.0072</td>\n      <td>0.5684</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7991.0</td>\n      <td>5.0774</td>\n      <td>6.50</td>\n      <td>-468.5135</td>\n      <td>4.7438</td>\n      <td>3.8186</td>\n      <td>92.4072</td>\n      <td>0.0390</td>\n      <td>0.3162</td>\n      <td>0.000</td>\n      <td>0.0909</td>\n      <td>0.5532</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       tokens_metric  document_entropy  word-length   coherence  uniform_dist  \\\n",
       "count      100.00000        100.000000   100.000000  100.000000    100.000000   \n",
       "mean     29768.04000          6.288914     6.266500 -419.502443      4.190007   \n",
       "std      27634.79199          1.222173     0.726833  123.424425      0.538936   \n",
       "min       4325.00000          4.395300     4.750000 -781.628300      2.639900   \n",
       "25%      11038.25000          5.205350     5.787500 -449.735150      3.778300   \n",
       "50%      18077.50000          5.940000     6.250000 -393.965050      4.150100   \n",
       "75%      37028.75000          7.451475     6.750000 -349.779900      4.613225   \n",
       "max     124161.00000          8.548600     8.000000 -204.155000      5.412500   \n",
       "\n",
       "       corpus_dist  eff_num_words  token-doc-diff  rank_1_docs  \\\n",
       "count   100.000000     100.000000      100.000000   100.000000   \n",
       "mean      3.034068     231.226355        0.017592     0.149840   \n",
       "std       0.705475     203.693676        0.016911     0.136242   \n",
       "min       1.563000      24.648700        0.000200     0.001300   \n",
       "25%       2.556000      86.061775        0.002225     0.019850   \n",
       "50%       3.075200     166.929350        0.014600     0.133750   \n",
       "75%       3.582775     319.326550        0.027675     0.256450   \n",
       "max       4.397000    1246.963300        0.078300     0.485700   \n",
       "\n",
       "       allocation_ratio  allocation_count  exclusivity  \n",
       "count        100.000000        100.000000   100.000000  \n",
       "mean           0.004375          0.053295     0.406579  \n",
       "std            0.011553          0.071661     0.176703  \n",
       "min            0.000000          0.000000     0.117200  \n",
       "25%            0.000000          0.002975     0.256950  \n",
       "50%            0.000000          0.017450     0.434750  \n",
       "75%            0.000900          0.080650     0.549775  \n",
       "max            0.063200          0.329500     0.793700  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens_metric</th>\n      <th>document_entropy</th>\n      <th>word-length</th>\n      <th>coherence</th>\n      <th>uniform_dist</th>\n      <th>corpus_dist</th>\n      <th>eff_num_words</th>\n      <th>token-doc-diff</th>\n      <th>rank_1_docs</th>\n      <th>allocation_ratio</th>\n      <th>allocation_count</th>\n      <th>exclusivity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100.00000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29768.04000</td>\n      <td>6.288914</td>\n      <td>6.266500</td>\n      <td>-419.502443</td>\n      <td>4.190007</td>\n      <td>3.034068</td>\n      <td>231.226355</td>\n      <td>0.017592</td>\n      <td>0.149840</td>\n      <td>0.004375</td>\n      <td>0.053295</td>\n      <td>0.406579</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>27634.79199</td>\n      <td>1.222173</td>\n      <td>0.726833</td>\n      <td>123.424425</td>\n      <td>0.538936</td>\n      <td>0.705475</td>\n      <td>203.693676</td>\n      <td>0.016911</td>\n      <td>0.136242</td>\n      <td>0.011553</td>\n      <td>0.071661</td>\n      <td>0.176703</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4325.00000</td>\n      <td>4.395300</td>\n      <td>4.750000</td>\n      <td>-781.628300</td>\n      <td>2.639900</td>\n      <td>1.563000</td>\n      <td>24.648700</td>\n      <td>0.000200</td>\n      <td>0.001300</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.117200</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11038.25000</td>\n      <td>5.205350</td>\n      <td>5.787500</td>\n      <td>-449.735150</td>\n      <td>3.778300</td>\n      <td>2.556000</td>\n      <td>86.061775</td>\n      <td>0.002225</td>\n      <td>0.019850</td>\n      <td>0.000000</td>\n      <td>0.002975</td>\n      <td>0.256950</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>18077.50000</td>\n      <td>5.940000</td>\n      <td>6.250000</td>\n      <td>-393.965050</td>\n      <td>4.150100</td>\n      <td>3.075200</td>\n      <td>166.929350</td>\n      <td>0.014600</td>\n      <td>0.133750</td>\n      <td>0.000000</td>\n      <td>0.017450</td>\n      <td>0.434750</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>37028.75000</td>\n      <td>7.451475</td>\n      <td>6.750000</td>\n      <td>-349.779900</td>\n      <td>4.613225</td>\n      <td>3.582775</td>\n      <td>319.326550</td>\n      <td>0.027675</td>\n      <td>0.256450</td>\n      <td>0.000900</td>\n      <td>0.080650</td>\n      <td>0.549775</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>124161.00000</td>\n      <td>8.548600</td>\n      <td>8.000000</td>\n      <td>-204.155000</td>\n      <td>5.412500</td>\n      <td>4.397000</td>\n      <td>1246.963300</td>\n      <td>0.078300</td>\n      <td>0.485700</td>\n      <td>0.063200</td>\n      <td>0.329500</td>\n      <td>0.793700</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "stemmed_experiment_metrics = diagnostics_xml_to_dataframe(stemmed_experiment_path /f'russian_novels_{stemmer}_100topics_1000iters_diagnostics.xml' ).rename(columns={\"tokens\":\"tokens_metric\"})\n",
    "display(stemmed_experiment_metrics.head())\n",
    "stemmed_experiment_metrics.describe()"
   ]
  }
 ]
}