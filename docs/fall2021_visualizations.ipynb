{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment organization\n",
    "Goal: Gather results from all topic modeling experiments using many stemming treatments for a particular corpus, then creates some visualizations.\n",
    "The expected tree structure for the corpus and experiments is as follows:\n",
    "```\n",
    "<corpus> # corpus name - 'tiger','rnc' or 'opencorpora'\n",
    "├── <corpus>_<stemmer> # stemmer or lemmatization treatment name, see topic_modeling/stemming.py for language details\n",
    "│   ├── <corpus_oracleAnalysis.gz # Only present when stemmer=='oracle', the annotation labels for the words in the corpus, in sequence to match up with state files\n",
    "│   ├── <corpus>_<stemmer>.mallet # mallet import-dir --output\n",
    "│   ├── <corpus>_<stemmer>.tsv # output of topic_modeling/corpus_preprocessing.py for this particular treatment\n",
    "│   ├── <corpus>_<stemmer>_<num_topics>_topics_<num_iters>_iters_<experiment_id> \n",
    "│   │   ├── <corpus>_<stemmer>_diagnostics.tsv # mallet train-topics metrics as tsv\n",
    "│   │   ├── <corpus>_<stemmer>_diagnostics.xml # original mallet train-topics metrics format\n",
    "│   │   ├── <corpus>_<stemmer>_doc_topics.txt # mallet train-topics --output-doc-topics \n",
    "│   │   ├── <corpus>_<stemmer>_entropy_metrics.tsv # metrics produced by by topic_modeling/mallet_parser slot-entropy\n",
    "│   │   ├── <corpus>_<stemmer>.model # mallet topic model \n",
    "│   │   ├── <corpus>_<stemmer>_postLemmatized_diagnostics.tsv # mallet train-topics metrics for the version of this model lifted to lemmas \n",
    "│   │   ├── <corpus>_<stemmer>_postLemmatized_diagnostics.xml \n",
    "│   │   ├── <corpus>_<stemmer>_postLemmatized.mallet # mallet corpus sequence file lifted to lemmas (we probably only need to create this once, but I didn't think of that earlier, so for now each experiment gets its own)\n",
    "│   │   ├── <corpus>_<stemmer>_postLemmatized.model # mallet topic model lifted to lemmas\n",
    "│   │   ├── <corpus>_<stemmer>_postLemmatized_state.gz # mallet topic model state file lifted to \n",
    "│   │   ├── <corpus>_<stemmer>_state.gz # mallet topic model state file\n",
    "│   │   ├── <corpus>_<stemmer>_top_docs.txt # mallet train-topics --output-doc-topics \n",
    "│   │   ├── <corpus>_<stemmer>_topic_keys.txt # mallet train-topics --output-topic-keys\n",
    "│   │   ├── <corpus>_<stemmer>_topic_lemmas.tsv # Counts and conditional probablilities of lemmas for each topic\n",
    "│   │   ├── <corpus>_<stemmer>_topic_pos.tsv  # Counts and conditional probablilities of parts-of-speech for each topic\n",
    "│   │   ├── <corpus>_<stemmer>_topic_slots.tsv  # Counts and conditional probablilities of detailed morphological analyses for each topic\n",
    "│   │   └── <corpus>_<stemmer>_top_terms.tsv # Raw counts of top 20 terms for each topic\n",
    "└── voi_<num_topics>_topics # Variation of information between different models for the same number of topics\n",
    "    └── <corpus>_<stemmer1>_<experiment1_id>_<corpus>_<stemmer2>_<experiment2_id>.tsv # Compares treatment 1 and treatment 2 \n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num experiment folders found: 107\n",
      "VOI folders: [PosixPath('/home/virginia/workspace/topic-modeling-study/tiger/voi_100_topics'), PosixPath('/home/virginia/workspace/topic-modeling-study/tiger/voi_50_topics')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "corpus_name = \"tiger\"\n",
    "corpus_root = Path(\"/home/virginia/workspace/topic-modeling-study\") / corpus_name\n",
    "experiment_folders = list(corpus_root.glob(f\"{corpus_name}_*/*_topics_*_iters_*\"))\n",
    "voi_folders = list(corpus_root.glob(f\"voi_*\"))\n",
    "print(\"Num experiment folders found:\", len(experiment_folders))\n",
    "print(\"VOI folders:\", voi_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def parse_experiment_directory(experiment_path):\n",
    "    dir_name = experiment_path.name\n",
    "    split_name = dir_name.split(\"_\")\n",
    "    corpus = split_name[0]\n",
    "    treatment = split_name[1]\n",
    "    num_topics = split_name[2]\n",
    "    experiment_id = split_name[-1]\n",
    "    original_mallet_diagnostics = pd.read_csv(experiment_path / f\"{corpus}_{treatment}_diagnostics.tsv\", sep=\"\\t\", index_col=\"id\")\n",
    "\n",
    "    final_frame = original_mallet_diagnostics\n",
    "\n",
    "    final_frame.insert(loc = 0, column=\"corpus\", value = corpus)\n",
    "    final_frame.insert(loc = 1, column=\"stemmer\", value=treatment)\n",
    "    final_frame.insert(loc = 2, column=\"experiment_id\", value = experiment_id)\n",
    "\n",
    "    lemma_mallet_diagnostics = pd.read_csv(experiment_path / f\"{corpus}_{treatment}_postLemmatized_diagnostics.tsv\", sep=\"\\t\", index_col=\"id\")\n",
    "    lemma_mallet_diagnostics.rename(columns = {\"exclusivity\":\"lemma_exclusivity\"}, inplace=True)\n",
    "    \n",
    "    final_frame[\"lemma_exclusivity\"] = lemma_mallet_diagnostics[\"lemma_exclusivity\"]\n",
    "\n",
    "    entropy_metrics = pd.read_csv(experiment_path / f\"{corpus}_{treatment}_entropy_metrics.tsv\", sep = \"\\t\", index_col=\"topic\")\n",
    "    entropy_metrics[\"num_lemmas_in_top_20_terms\"] = len(entropy_metrics[\"lemmas_in_20_terms\"])\n",
    "\n",
    "    final_frame = pd.merge(final_frame, entropy_metrics, left_index= True, right_index = True)\n",
    "\n",
    "\n",
    "    return final_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>stemmer</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>document_entropy</th>\n",
       "      <th>word-length</th>\n",
       "      <th>coherence</th>\n",
       "      <th>uniform_dist</th>\n",
       "      <th>corpus_dist</th>\n",
       "      <th>eff_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>slot_entropy</th>\n",
       "      <th>pos_entropy</th>\n",
       "      <th>lemmas_to_top_20_surface_forms</th>\n",
       "      <th>slots_to_top_20_surface_forms</th>\n",
       "      <th>pos_to_top_20_surface_forms</th>\n",
       "      <th>top_20_term_set</th>\n",
       "      <th>top_20_lemma_set</th>\n",
       "      <th>lemmas_in_20_terms</th>\n",
       "      <th>top_lemmas_minus_top_term_lemmas</th>\n",
       "      <th>num_top_lemmas_excluded_by_top_terms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>snowball</td>\n",
       "      <td>8</td>\n",
       "      <td>5495.0</td>\n",
       "      <td>4.9217</td>\n",
       "      <td>6.55</td>\n",
       "      <td>-390.2468</td>\n",
       "      <td>4.1912</td>\n",
       "      <td>3.1576</td>\n",
       "      <td>297.1045</td>\n",
       "      <td>...</td>\n",
       "      <td>5.847058</td>\n",
       "      <td>2.268032</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>{'deutschland', 'mensch', 'volk', 'evangel', '...</td>\n",
       "      <td>{'Volk', 'EKD', 'Welt', 'sozial', 'Krieg', 'Ki...</td>\n",
       "      <td>{'verantworten', 'Evangele', 'Volk', 'Politike...</td>\n",
       "      <td>{'EKD', 'Christ'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>snowball</td>\n",
       "      <td>8</td>\n",
       "      <td>3142.0</td>\n",
       "      <td>3.8596</td>\n",
       "      <td>5.75</td>\n",
       "      <td>-545.4456</td>\n",
       "      <td>4.1048</td>\n",
       "      <td>3.8789</td>\n",
       "      <td>450.1671</td>\n",
       "      <td>...</td>\n",
       "      <td>5.725491</td>\n",
       "      <td>2.166171</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'land', 'mexiko', 'sri', 'san', 'sud', 'stadt...</td>\n",
       "      <td>{'Mexiko', 'Meer', 'Land', 'Süden', 'Stadt', '...</td>\n",
       "      <td>{'Mexiko', 'Meer', 'Land', 'Philippinen', 'Nor...</td>\n",
       "      <td>{'Jaffna', 'Chamula'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>snowball</td>\n",
       "      <td>8</td>\n",
       "      <td>7373.0</td>\n",
       "      <td>5.0547</td>\n",
       "      <td>6.50</td>\n",
       "      <td>-313.2359</td>\n",
       "      <td>4.1087</td>\n",
       "      <td>2.8627</td>\n",
       "      <td>322.3903</td>\n",
       "      <td>...</td>\n",
       "      <td>5.616719</td>\n",
       "      <td>2.050576</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>{'weltweit', 'siem', 'umsatz', 'million', 'erl...</td>\n",
       "      <td>{'weltweit', 'Unternehmen', 'Million', 'Aktion...</td>\n",
       "      <td>{'weltweit', 'erlösen', 'Unternehmen', 'Millio...</td>\n",
       "      <td>{'Belegschaft', 'übernehmen'}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiger</td>\n",
       "      <td>snowball</td>\n",
       "      <td>8</td>\n",
       "      <td>9029.0</td>\n",
       "      <td>4.2369</td>\n",
       "      <td>8.40</td>\n",
       "      <td>-248.3175</td>\n",
       "      <td>4.1628</td>\n",
       "      <td>2.6433</td>\n",
       "      <td>273.8653</td>\n",
       "      <td>...</td>\n",
       "      <td>5.710308</td>\n",
       "      <td>2.005119</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>{'deutschland', 'mensch', 'offent', 'arbeit', ...</td>\n",
       "      <td>{'Arbeit', 'Unternehmen', 'sozial', 'ökonomisc...</td>\n",
       "      <td>{'Arbeit', 'Politiker', 'arbeiten', 'National'...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tiger</td>\n",
       "      <td>snowball</td>\n",
       "      <td>8</td>\n",
       "      <td>4267.0</td>\n",
       "      <td>4.3778</td>\n",
       "      <td>7.60</td>\n",
       "      <td>-374.0873</td>\n",
       "      <td>4.4821</td>\n",
       "      <td>3.4902</td>\n",
       "      <td>184.7049</td>\n",
       "      <td>...</td>\n",
       "      <td>5.661638</td>\n",
       "      <td>1.796045</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>{'arbeitgeb', 'kundig', 'arbeitnehm', 'arbeit'...</td>\n",
       "      <td>{'Arbeit', 'Unternehmen', 'Medium', 'Gewerksch...</td>\n",
       "      <td>{'Arbeit', 'kundig', 'betreiben', 'arbeiten', ...</td>\n",
       "      <td>{'Medium', 'Arbeitszeit', 'DGB', 'schaffen'}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpus   stemmer experiment_id  tokens  document_entropy  word-length  \\\n",
       "id                                                                         \n",
       "0   tiger  snowball             8  5495.0            4.9217         6.55   \n",
       "1   tiger  snowball             8  3142.0            3.8596         5.75   \n",
       "2   tiger  snowball             8  7373.0            5.0547         6.50   \n",
       "3   tiger  snowball             8  9029.0            4.2369         8.40   \n",
       "4   tiger  snowball             8  4267.0            4.3778         7.60   \n",
       "\n",
       "    coherence  uniform_dist  corpus_dist  eff_num_words  ...  slot_entropy  \\\n",
       "id                                                       ...                 \n",
       "0   -390.2468        4.1912       3.1576       297.1045  ...      5.847058   \n",
       "1   -545.4456        4.1048       3.8789       450.1671  ...      5.725491   \n",
       "2   -313.2359        4.1087       2.8627       322.3903  ...      5.616719   \n",
       "3   -248.3175        4.1628       2.6433       273.8653  ...      5.710308   \n",
       "4   -374.0873        4.4821       3.4902       184.7049  ...      5.661638   \n",
       "\n",
       "    pos_entropy  lemmas_to_top_20_surface_forms  \\\n",
       "id                                                \n",
       "0      2.268032                            2.10   \n",
       "1      2.166171                            1.55   \n",
       "2      2.050576                            1.45   \n",
       "3      2.005119                            1.95   \n",
       "4      1.796045                            2.15   \n",
       "\n",
       "    slots_to_top_20_surface_forms  pos_to_top_20_surface_forms  \\\n",
       "id                                                               \n",
       "0                            3.25                         0.30   \n",
       "1                            2.90                         0.25   \n",
       "2                            3.00                         0.35   \n",
       "3                            3.30                         0.35   \n",
       "4                            3.65                         0.35   \n",
       "\n",
       "                                      top_20_term_set  \\\n",
       "id                                                      \n",
       "0   {'deutschland', 'mensch', 'volk', 'evangel', '...   \n",
       "1   {'land', 'mexiko', 'sri', 'san', 'sud', 'stadt...   \n",
       "2   {'weltweit', 'siem', 'umsatz', 'million', 'erl...   \n",
       "3   {'deutschland', 'mensch', 'offent', 'arbeit', ...   \n",
       "4   {'arbeitgeb', 'kundig', 'arbeitnehm', 'arbeit'...   \n",
       "\n",
       "                                     top_20_lemma_set  \\\n",
       "id                                                      \n",
       "0   {'Volk', 'EKD', 'Welt', 'sozial', 'Krieg', 'Ki...   \n",
       "1   {'Mexiko', 'Meer', 'Land', 'Süden', 'Stadt', '...   \n",
       "2   {'weltweit', 'Unternehmen', 'Million', 'Aktion...   \n",
       "3   {'Arbeit', 'Unternehmen', 'sozial', 'ökonomisc...   \n",
       "4   {'Arbeit', 'Unternehmen', 'Medium', 'Gewerksch...   \n",
       "\n",
       "                                   lemmas_in_20_terms  \\\n",
       "id                                                      \n",
       "0   {'verantworten', 'Evangele', 'Volk', 'Politike...   \n",
       "1   {'Mexiko', 'Meer', 'Land', 'Philippinen', 'Nor...   \n",
       "2   {'weltweit', 'erlösen', 'Unternehmen', 'Millio...   \n",
       "3   {'Arbeit', 'Politiker', 'arbeiten', 'National'...   \n",
       "4   {'Arbeit', 'kundig', 'betreiben', 'arbeiten', ...   \n",
       "\n",
       "                top_lemmas_minus_top_term_lemmas  \\\n",
       "id                                                 \n",
       "0                              {'EKD', 'Christ'}   \n",
       "1                          {'Jaffna', 'Chamula'}   \n",
       "2                  {'Belegschaft', 'übernehmen'}   \n",
       "3                                          set()   \n",
       "4   {'Medium', 'Arbeitszeit', 'DGB', 'schaffen'}   \n",
       "\n",
       "    num_top_lemmas_excluded_by_top_terms  \n",
       "id                                        \n",
       "0                                      2  \n",
       "1                                      2  \n",
       "2                                      2  \n",
       "3                                      0  \n",
       "4                                      4  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_frame = parse_experiment_directory(experiment_folders[0])\n",
    "test_frame.columns\n",
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e033f2c49d4eafd90655d62518a289d9aca32574a1cc9cfd9e072312f61821b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('topic_modeling': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
